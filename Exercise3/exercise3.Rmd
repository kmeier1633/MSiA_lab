---
title: 'Analytics for Competitive Advantage: Lab Exercise 3'
author: "Kristin Meier"
date: "November 15, 2016"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Problem 1

```{r, echo=F}
filepath <- "/Users/kmeier92/Documents/Northwestern/fall2016/Competitive_Analytics/labs/exercises/data/"
```

## Problem 1(a) 
### Build a regression model reg and display summary() of the model. Pick two explanatory variables that are least likely to be in the best model, and support your suggestion in one sentence.
```{r}
housing <- read.table(paste(filepath,"ex3_bostonhousing.txt",sep=""),stringsAsFactors = F,header=T)

# MEDV is the response variable
reg <- lm(MEDV ~ CRIM + ZN + INDUS + CHAS + NOX + RM + AGE + 
            DIS + RAD + TAX + PTRATIO + B + LSTAT, housing)
summary(reg)

# Find which have the max 2 p-values
pvals.reg <- summary(reg)$coefficients[,4]
max2 <- sort(pvals.reg,decreasing=T)[1:2]
max.val <- rownames(summary(reg)$coefficients)[which(pvals.reg %in% max2)]
```

The two explanatory variables that are least likely to be in the best model are `r max.val[1]` and `r max.val[2]`, based on the fact that the coefficient estimates for these predictors are not statistically significant and have the highest p-values of `r round(max2[1],3)` and `r round(max2[2],3)`, respectively.

## Problem 1(b)
### Build regression model reg.picked by excluding the two explanatory variables selected in problem 1(a). Display summary() of the model.
```{r}
# exclude INDUS and AGE
reg.picked <- lm(MEDV ~ CRIM + ZN + CHAS + NOX + RM + 
            DIS + RAD + TAX + PTRATIO + B + LSTAT, housing)
summary(reg.picked)

```

## Problem 1(c)
### For a regression model, the mean squared squared error (MSE) is defined as $\frac{SSE}{n-1-p}$, in which $p$ is the number of explanatory variables used in the model. The mean absolute error (MAE) is similarly defined: $\frac{SAE}{n-1-p}$. Display MSE and MAE for regression models reg and reg.picked from the previous problems. Based on MSE and MAE, pick one model you prefer. 
```{r}
# MAE assigns equal weight to the data whereas MSE emphasizes the extremes.
# MAE gives equal weight to all errors, while RMSE gives extra weight to large errors.

# use predict to predict the values
actual <- housing$MEDV
pred.reg <- predict(reg, housing)
pred.reg.picked <- predict(reg.picked, housing)
error.reg <- actual - pred.reg
error.reg.picked <- actual - pred.reg.picked

# MSE
# mse.reg <- anova(reg)["Residuals","Mean Sq"]
# mse.reg.picked <- anova(reg.picked)["Residuals","Mean Sq"]
mse.reg <- mean(error.reg^2)
mse.reg.picked <- mean(error.reg.picked^2)

# MAE
mae.reg <- mean(abs(error.reg))
mae.reg.picked <- mean(abs(error.reg.picked))

round(data.frame(mse.reg,mse.reg.picked,mae.reg,mae.reg.picked),3)
```

Based on MSE and MAE, I pick the model that minimizes these values, which is the reg model. The MSE and MAE are `r round(mse.reg,3)` and `r round(mae.reg,3)` (`r round(mse.reg.picked,3)` and `r round(mae.reg.picked,3)` for the reg.picked model). 

## Problem 1(d)
### Run step() using regression model reg in problem 1(a). Compare the model with reg.picked in problem 1(b).
```{r}
# from lab
library(MASS)
 reg = lm(MEDV~., data=housing)
 reg.step = stepAIC(object=reg, direction="both")

```

After running the step function to select a model, the result contains the same variables from part 1(b).
(CRIM, ZN, B, CHAS, NOX, RM, DIS, RAD, TAX, PTRATIO, LSTAT)

# Probelm 2

## Problem 2(a)
### Build regression model reg and display summary() of the model
```{r}
lab <- read.table(paste(filepath,"ex3_labdata.txt",sep=""),stringsAsFactors = F,header=T)

# regression
reg <- lm(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8, lab)
summary(reg)
```

## Problem 2(b)
### For each explanatory variable, plot it against the response variable. Based on the scatter plots, pick one variable that is most likely to be used in a piecewise regression model. Attach one plot associated with the variable you pick.
```{r}
#par(omi = c(.75,.75,.75,.75), mar = c(5,4,2,2))
#layout(matrix(c(1,2),ncol=1, byrow = TRUE))
'
for(i in 2:ncol(lab)){
  plot(x=lab[,i],
       y=lab[,1],
       xlab = colnames(lab)[i],
       ylab = colnames(lab)[1])
}
'
# just plot x1
  plot(x=lab[,2],
       y=lab[,1],
       xlab = colnames(lab)[2],
       ylab = colnames(lab)[1])

```

The explanatory variable most likely to be used in a piecewise regression model is x1. From the scatter plot it is clear that the data display different patterns before and after a cricial point (around x1=15). The other variables do not have a clear break in their relationship with y.

## Problem 2(c)
### Calculate the mean of the variable you pick in problem 2(b) and build piecewise regression model reg.piece using the mean. Is model reg.piece better than model reg in problem 2(a)? Support your argument in one sentence.
```{r}
var.picked <- "x1"
var.mean <- mean(lab[,var.picked])

#install.packages("segmented")
library(segmented)

reg.piece = segmented(reg, seg.Z = ~x1, psi=var.mean)
summary(reg.piece)

# interpret as coef.x1*x1 + coef.U1.x1*1_x1<mean

# SSE
sse.reg <- round(anova(reg)["Residuals","Sum Sq"],3)
sse.piece <- round(anova(reg.piece)["Residuals","Sum Sq"],3)
# R2
r2.reg <- round(summary(reg)$r.squared,3)
r2.piece <- round(summary(reg.piece)$r.squared,3)
# F value
f.reg <- round(summary(reg)$fstatistic[1],3)
f.piece <- round(summary(reg.piece)$fstatistic[1],3)
# num predictors significant

sse.piece < sse.reg
r2.piece > r2.reg
f.piece > f.reg

```

The regpiece model is better than the reg model because although less variables are significant, it outperforms the reg model by all other measures, namely SSE, $R^2$, and F-value. 

